Uruchamianie:
    export HADOOP_HOME=...
    ./init-hadoop.sh
    ./run-cc-giraph.sh


Opis rozwiązania:

    1. Budowanie: Oparte całkowicie na mavenie. 

       Konieczne zależności dociągane są automatycznie przez 
       mavena z internetu = nie jest potrzebna lokalna instalacja Girapha. 
       Wystarczy Hadoop.
       Uwaga: wersja Girapha jaką uzywaliśmy na labach była wersją rozwojową 
       (1.3-snapshot), w swoim rozwiązaniu użyłem wersji stabilnej - release 1.2.

    2. Algorytm CC:

       1) znajdź wierzchołek o największym stopniu używając agregatora - pivot
       2) propaguj pivota
       3) normalny algorytm CC na pozostalych wierzcholkach - wysyłaj sąsiadom 
          wierzchołem o najniższym id dotąd widziany

       Kolejne fazy zarzadzane są przez zaimplementowanego Mastera, 
       wspomaganego kolejnymi dwoma agregatorami.


Porównanie statystyk na grafie dblp-2011:

    CC z Single Pivot:
		Aggregate sent message bytes=52771827
		Aggregate sent messages=6596119
		Aggregate vertices=986324
		Superstep=23
        Total (ms)=91130

        UWAGA: w tym 14 superstepow propagate pivot
        oraz 7 superstepow normalnych

    CC bez Single Pivot


Konkluzja: 

    Optymalizacja oparta na heurystyce Single Pivot zmniejsza komunikację. 
    Minusem jest zwiększona ilość superstepów. Na ten problem możnaby 
    zaradzić pomysł proponowany w pracy stosując górny limit superstepów 
    na fazę propagowania pivota - moje rozwiązanie nie uwzględnia tego pomysłu.


Notatki własne - komendy pomocnicze:

    obliczenie ilosci spojnych skladowych:
    $HADOOP_HOME/bin/hdfs dfs -cat /user/wos_michal/output/part* 2>/dev/null | cut -f2 | sort | uniq | wc -l

    logi z mastera: 
    grep "mimuw.CCSinglePivotMaster" run.log


