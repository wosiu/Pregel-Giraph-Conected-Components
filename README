Uruchamianie:
    export HADOOP_HOME=...
    ./init-hadoop.sh
    ./run-cc-giraph.sh sciezka/lokalna/do/pliku/wejsciowego/z/grafem

Opis rozwiązania:

    1. Budowanie: Oparte całkowicie na mavenie. 

       Konieczne zależności dociągane są automatycznie przez 
       mavena z internetu = nie jest potrzebna lokalna instalacja Girapha. 
       Wystarczy Hadoop.
       Uwaga: wersja Girapha jaką uzywaliśmy na labach była wersją rozwojową 
       (1.3-snapshot), w swoim rozwiązaniu użyłem wersji stabilnej - release 1.2.

    2. Algorytm CC:

       1) znajdź wierzchołek o największym stopniu używając agregatora - pivot
       2) propaguj pivota
       3) normalny algorytm CC na pozostalych wierzcholkach - wysyłaj sąsiadom 
          wierzchołem o najniższym id dotąd widziany

       Kod java: giraph-cc/src/main/java/org/apache/giraph/examples/mimuw
       Kolejne fazy zarzadzane są przez zaimplementowanego Mastera, 
       wspomaganego kolejnymi dwoma agregatorami.


Porównanie statystyk na grafie dblp-2011:

    CC z Single Pivot:
		Aggregate sent message bytes=52771827
		Aggregate sent messages=6596119
		Aggregate vertices=986324
		Superstep=23
        AVERAGE Total (ms) = (91130 + 90911 + 91814) / 3 = 91285

        UWAGA: w tym 14 superstepow propagate pivot
        oraz 7 superstepow normalnych

    CC bez Single Pivot (orginalny z exampli apache: 
    org.apache.giraph.examples.original.ConnectedComponentsComputation):
		Aggregate sent message bytes=235709651
		Aggregate sent messages=29462272
		Aggregate vertices=986324
		Superstep=15
		ACVERAGE Total (ms)= ( 88895 + 89002 + 90137) / 3 = 89345


Konkluzja: 

    Optymalizacja oparta na heurystyce Single Pivot zmniejsza ponad >> 4 krotnie << komunikację. 
    Minusem jest zwiększona ilość superstepów, choć ostateczne czasy dzialania nie różnią się znacznie. 
    Na problem zwiększonej ilości supestepów możnaby próbować zaradzić stosując górny limit 
    superstepów na fazę propagowania pivota - moje rozwiązanie nie uwzględnia tego pomysłu.


Notatki własne - komendy pomocnicze:

    obliczenie ilosci spojnych skladowych:
    $HADOOP_HOME/bin/hdfs dfs -cat /user/wos_michal/output/part* 2>/dev/null | cut -f2 | sort | uniq | wc -l

    logi z mastera: 
    grep "mimuw.CCSinglePivotMaster" run.log


